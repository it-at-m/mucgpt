from decimal import Decimal
from typing import List, Literal, Optional

from pydantic import BaseModel, ConfigDict, Field, PositiveInt


class SummarizeResult(BaseModel):
    """Result model for the summarize endpoint."""

    answer: List[str] = Field(
        ..., description="The summarized text as a list of strings."
    )
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "answer": [
                    "Project status: On track.",
                    "Pending tasks: finalize API docs, complete load tests.",
                ]
            }
        }
    )


class SumRequest(BaseModel):
    """Request model for the summarize endpoint."""

    text: str = Field("", description="The text to summarize.")
    detaillevel: Optional[str] = Field(
        "short",
        description="The desired level of detail for the summary (e.g., 'short', 'medium', 'long').",
    )
    language: Optional[str] = Field(
        "Deutsch", description="The language of the summary."
    )
    model: str = Field("gpt-4o-mini", description="The model to use for summarization.")
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "text": "Das Projekt Meeting behandelte den aktuellen Fortschritt und die n√§chsten Schritte.",
                "detaillevel": "short",
                "language": "Deutsch",
                "model": "gpt-4o-mini",
            }
        }
    )


class ChatCompletionMessage(BaseModel):
    # follow openai chat completion API model structure

    role: Literal["system", "user", "assistant"] = Field(
        ..., description="Message role: system, user, or assistant"
    )
    content: str = Field(..., description="The message content")
    model_config = ConfigDict(
        json_schema_extra={
            "example": {"role": "user", "content": "List three benefits of unit tests."}
        }
    )


class ChatCompletionRequest(BaseModel):
    model: str = Field("gpt-4o-mini", description="The model to use")
    messages: List[ChatCompletionMessage] = Field(
        ..., description="Sequence of messages in the conversation"
    )
    temperature: Optional[float] = Field(0.7, description="Sampling temperature")
    stream: Optional[bool] = Field(
        False, description="Whether to stream partial responses back"
    )
    enabled_tools: Optional[List[str]] = Field(
        None, description="List of enabled tool IDs for this completion request"
    )
    assistant_id: Optional[str] = Field(
        None, description="ID of the assistant to use for this completion request"
    )
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "You are concise."},
                    {"role": "user", "content": "Explain test driven development."},
                ],
                "temperature": 0.5,
                "stream": False,
                "enabled_tools": ["Vereinfachen"],
                "assistant_id": "assistant-123",
            }
        }
    )


class ChatCompletionChoice(BaseModel):
    index: int
    message: ChatCompletionMessage
    finish_reason: Optional[str] = Field(
        None, description="Why the model stopped generating"
    )
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "TDD ensures code correctness, guides design, and enables refactoring.",
                },
                "finish_reason": "stop",
            }
        }
    )


class Usage(BaseModel):
    prompt_tokens: int = Field(
        ..., description="Number of tokens in the prompt/messages"
    )
    completion_tokens: int = Field(
        ..., description="Number of tokens generated by the model"
    )
    total_tokens: int = Field(..., description="Total tokens consumed")
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "prompt_tokens": 120,
                "completion_tokens": 85,
                "total_tokens": 205,
            }
        }
    )


class ChatCompletionResponse(BaseModel):
    id: str = Field(..., description="Unique ID for this completion")
    object: str = Field("chat.completion", description="Type of object returned")
    created: int = Field(..., description="Unix timestamp for creation")
    choices: List[ChatCompletionChoice] = Field(
        ..., description="List of completion choices"
    )
    usage: Usage = Field(..., description="Token usage information")
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "id": "chatcmpl-xyz",
                "object": "chat.completion",
                "created": 1710000000,
                "choices": [
                    {
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": "TDD improves reliability, supports refactoring, and documents behavior.",
                        },
                        "finish_reason": "stop",
                    }
                ],
                "usage": {
                    "prompt_tokens": 50,
                    "completion_tokens": 25,
                    "total_tokens": 75,
                },
            }
        }
    )


class ChatCompletionDelta(BaseModel):
    """Incremental content update for streaming responses"""

    role: Optional[Literal["system", "user", "assistant"]] = Field(
        None,
        description="Role indicated when provided (assistant only after initial chunk)",
    )
    content: Optional[str] = Field(None, description="New content for this chunk")
    tool_calls: Optional[List[dict]] = Field(None, description="Tool call information")
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "role": "assistant",
                "content": "TDD ensures code quality",
                "tool_calls": [],
            }
        }
    )


class ChatCompletionChunkChoice(BaseModel):
    """A single choice in a streaming chunk"""

    delta: ChatCompletionDelta = Field(..., description="Partial message update")
    index: int = Field(..., description="Choice index, always 0 for single-stream")
    finish_reason: Optional[str] = Field(
        None, description="Why the stream stopped for this choice"
    )
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "delta": {"role": "assistant", "content": "TDD", "tool_calls": []},
                "index": 0,
                "finish_reason": None,
            }
        }
    )


class ChatCompletionChunk(BaseModel):
    """Streaming chunk of chat completion, in ndjson format"""

    id: str = Field(..., description="Same ID as the full completion request")
    object: Literal["chat.completion.chunk"] = Field(
        "chat.completion.chunk", description="Type of object returned"
    )
    created: int = Field(..., description="Unix timestamp for chunk creation")
    choices: List[ChatCompletionChunkChoice] = Field(
        ..., description="List of partial choices for this chunk"
    )
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "id": "chatcmpl-xyz",
                "object": "chat.completion.chunk",
                "created": 1710000001,
                "choices": [
                    {
                        "delta": {
                            "role": "assistant",
                            "content": "TDD",
                            "tool_calls": [],
                        },
                        "index": 0,
                        "finish_reason": None,
                    }
                ],
            }
        }
    )


class ToolInfo(BaseModel):
    """Detailed information about a tool."""

    id: str = Field(..., description="Tool ID.")
    name: str = Field(..., description="Tool name.")
    description: str = Field(..., description="Description of the tool.")
    # Optionally, add more fields like parameters if needed
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "id": "WEB_SEARCH",
                "name": "Web Search",
                "description": "Search the municipal website for information.",
            }
        }
    )


class ToolListResponse(BaseModel):
    """Response model for listing available tools with details."""

    tools: List[ToolInfo] = Field(
        ..., description="List of available tools with details."
    )
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "tools": [
                    {
                        "id": "WEB_SEARCH",
                        "name": "Web Search",
                        "description": "Search the municipal website for information.",
                    }
                ]
            }
        }
    )


class CreateAssistantRequest(BaseModel):
    """Request model for creating a assistant."""

    input: str = Field(..., description="The input to create the assistant.")
    model: str = Field(
        "gpt-4o-mini", description="The model to use for assistant creation."
    )
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "input": "Create an assistant that answers questions about internal IT policies.",
                "model": "gpt-4o-mini",
            }
        }
    )


class CreateAssistantResult(BaseModel):
    """Result model for creating a assistant."""

    system_prompt: str = Field(..., description="The system prompt for the assistant.")
    description: str = Field(..., description="The description of the assistant.")
    title: str = Field(..., description="The title of the assistant.")
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "system_prompt": "You are an assistant specialized in internal IT policy guidance.",
                "description": "Provides answers about acceptable use, data handling, and security practices.",
                "title": "IT Policy Assistant",
            }
        }
    )


class ModelsDTO(BaseModel):
    llm_name: str = Field(..., description="Identifier of the model/deployment")
    max_input_tokens: PositiveInt | None = Field(
        None, description="Maximum tokens the model can receive as input"
    )
    description: str | None = Field(None, description="Human-readable summary")
    input_cost_per_token: Decimal | None = Field(
        None, description="Input pricing information per token"
    )
    output_cost_per_token: Decimal | None = Field(
        None, description="Output pricing information per token"
    )
    supports_function_calling: bool | None = Field(
        None, description="Whether the model supports structured tool/function calls"
    )
    supports_reasoning: bool | None = Field(
        None, description="Whether enhanced reasoning is available"
    )
    supports_vision: bool | None = Field(
        None, description="Whether multimodal vision inputs are supported"
    )
    litellm_provider: str | None = Field(
        None, description="Provider identifier reported by LiteLLM"
    )
    inference_location: str | None = Field(
        None, description="Physical or logical inference region"
    )
    knowledge_cut_off: str | None = Field(
        None, description="Last known training data cutoff for the model"
    )


class ConfigResponse(BaseModel):
    env_name: str = "MUCGPT"
    alternative_logo: bool = False
    models: List[ModelsDTO] = Field(
        default_factory=list,
        description="List of configured language models",
    )
    core_version: str
    frontend_version: str
    assistant_version: str
