{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import openai\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALLUSERSPROFILE': 'C:\\\\ProgramData',\n",
       " 'APPDATA': 'C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Roaming',\n",
       " 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files',\n",
       " 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMPUTERNAME': 'NBO00359842',\n",
       " 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe',\n",
       " 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData',\n",
       " 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer',\n",
       " 'FPS_BROWSER_USER_PROFILE_STRING': 'Default',\n",
       " 'HOMEDRIVE': 'C:',\n",
       " 'HOMEPATH': '\\\\Users\\\\michael.jaumann',\n",
       " 'HTTPS_PROXY': 'http://internet-proxy-client.muenchen.de:80',\n",
       " 'JAVA_HOME': 'C:\\\\Program Files\\\\Java\\\\jdk-17',\n",
       " 'LHM_VERSION': '20H2_OSD',\n",
       " 'LOCALAPPDATA': 'C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Local',\n",
       " 'LOGONSERVER': '\\\\\\\\DCWIP101',\n",
       " 'MAVEN_HOME': 'C:\\\\Program Files\\\\apache-maven-3.9.5',\n",
       " 'NODE_HOME': 'C:\\\\Program Files\\\\nodejs\\\\',\n",
       " 'NUMBER_OF_PROCESSORS': '8',\n",
       " 'ONEDRIVE': 'C:\\\\Users\\\\michael.jaumann\\\\OneDrive',\n",
       " 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined',\n",
       " 'OS': 'Windows_NT',\n",
       " 'PATH': 'C:\\\\Programme\\\\Java\\\\jre-21\\\\bin;C:\\\\Programme\\\\Java\\\\jre-17\\\\bin;C:\\\\Programme\\\\Java\\\\jre-11\\\\bin;C:\\\\Programme\\\\Java\\\\jdk-17\\\\bin;C:\\\\Programme\\\\Java\\\\jdk-11\\\\bin;C:\\\\Program Files\\\\Python38\\\\Scripts\\\\;C:\\\\Program Files\\\\Python38\\\\;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files (x86)\\\\Webex\\\\Plugins;C:\\\\Program Files\\\\nodejs\\\\;C:\\\\Program Files\\\\apache-maven-3.8.1\\\\bin;C:\\\\Program Files\\\\nodejs\\\\;C:\\\\Program Files\\\\apache-maven-3.8.7\\\\bin;C:\\\\Program Files (x86)\\\\Plantronics\\\\Spokes3G SDK\\\\;C:\\\\Program Files\\\\apache-maven-3.9.5\\\\bin;C:\\\\Program Files\\\\Helm;C:\\\\Program Files\\\\LibreOffice 6\\\\program;C:\\\\Program Files\\\\openshift;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Roaming\\\\npm;C:\\\\Users\\\\michael.jaumann\\\\develop\\\\programme\\\\data-integration;C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Local\\\\Programs\\\\Azure Dev CLI\\\\',\n",
       " 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW;.CPL',\n",
       " 'PENTAHO_JAVA_HOME': 'C:\\\\Program Files\\\\Java\\\\jre8',\n",
       " 'PROCESSOR_ARCHITECTURE': 'AMD64',\n",
       " 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 140 Stepping 1, GenuineIntel',\n",
       " 'PROCESSOR_LEVEL': '6',\n",
       " 'PROCESSOR_REVISION': '8c01',\n",
       " 'PROGRAMDATA': 'C:\\\\ProgramData',\n",
       " 'PROGRAMFILES': 'C:\\\\Program Files',\n",
       " 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)',\n",
       " 'PROGRAMW6432': 'C:\\\\Program Files',\n",
       " 'PSEXECUTIONPOLICYPREFERENCE': 'bypass',\n",
       " 'PSMODULEPATH': 'C:\\\\Users\\\\michael.jaumann\\\\Documents\\\\WindowsPowerShell\\\\Modules;C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules',\n",
       " 'PUBLIC': 'C:\\\\Users\\\\Public',\n",
       " 'SESSIONNAME': 'Console',\n",
       " 'SYSTEMDRIVE': 'C:',\n",
       " 'SYSTEMROOT': 'C:\\\\WINDOWS',\n",
       " 'TEMP': 'C:\\\\Users\\\\MICHAE~1.JAU\\\\AppData\\\\Local\\\\Temp',\n",
       " 'TMP': 'C:\\\\Users\\\\MICHAE~1.JAU\\\\AppData\\\\Local\\\\Temp',\n",
       " 'UATDATA': 'C:\\\\WINDOWS\\\\CCM\\\\UATData\\\\D9F8C395-CAB8-491d-B8AC-179A1FE1BE77',\n",
       " 'UEMCONFIGSHARE': 'C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Local\\\\VMware DEM\\\\FlexSync\\\\General',\n",
       " 'UEMPROFILEARCHIVEBACKUPS': 'C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Local\\\\VMware DEM\\\\FlexSync\\\\Profile Archive Backups',\n",
       " 'UEMPROFILEARCHIVES': 'C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Local\\\\VMware DEM\\\\FlexSync\\\\Profile Archives',\n",
       " 'UEMSCRIPTS': 'C:\\\\Users\\\\michael.jaumann\\\\AppData\\\\Local\\\\VMware DEM\\\\FlexSync\\\\General\\\\FlexRepository\\\\Scripts',\n",
       " 'UEMSESSIONID': '1',\n",
       " 'UNO_JAVA_JFW_JREHOME': 'file:///C:/Programme/Java/jre-11',\n",
       " 'UNO_JAVA_JFW_PARAMETER_1': '-Xmx4096M',\n",
       " 'USERDNSDOMAIN': 'MUENCHEN.DE',\n",
       " 'USERDOMAIN': 'MUENCHEN',\n",
       " 'USERDOMAIN_ROAMINGPROFILE': 'MUENCHEN',\n",
       " 'USERNAME': 'michael.jaumann',\n",
       " 'USERPROFILE': 'C:\\\\Users\\\\michael.jaumann',\n",
       " 'WINDIR': 'C:\\\\WINDOWS',\n",
       " 'ZES_ENABLE_SYSMAN': '1',\n",
       " 'TERM_PROGRAM': 'vscode',\n",
       " 'TERM_PROGRAM_VERSION': '1.84.2',\n",
       " 'LANG': 'en_US.UTF-8',\n",
       " 'COLORTERM': 'truecolor',\n",
       " 'GIT_ASKPASS': 'c:\\\\Program Files\\\\Microsoft VS Code\\\\resources\\\\app\\\\extensions\\\\git\\\\dist\\\\askpass.sh',\n",
       " 'VSCODE_GIT_ASKPASS_NODE': 'C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe',\n",
       " 'VSCODE_GIT_ASKPASS_EXTRA_ARGS': '--ms-enable-electron-run-as-node',\n",
       " 'VSCODE_GIT_ASKPASS_MAIN': 'c:\\\\Program Files\\\\Microsoft VS Code\\\\resources\\\\app\\\\extensions\\\\git\\\\dist\\\\askpass-main.js',\n",
       " 'VSCODE_GIT_IPC_HANDLE': '\\\\\\\\.\\\\pipe\\\\vscode-git-2796e53623-sock',\n",
       " 'VSCODE_INJECTION': '1',\n",
       " 'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       " 'JPY_SESSION_NAME': 'C:\\\\Users\\\\michael.jaumann\\\\develop\\\\azure-search-openai\\\\notebooks\\\\chat.ipynb',\n",
       " 'JPY_INTERRUPT_EVENT': '3380',\n",
       " 'IPY_INTERRUPT_EVENT': '3380',\n",
       " 'JPY_PARENT_PID': '3356',\n",
       " 'TERM': 'xterm-color',\n",
       " 'CLICOLOR': '1',\n",
       " 'FORCE_COLOR': '1',\n",
       " 'CLICOLOR_FORCE': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
       " 'HTTP_PROXY': 'http://internet-proxy-client.muenchen.de:80'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = \"http://internet-proxy-client.muenchen.de:80\" \n",
    "os.environ['HTTPS_PROXY'] = \"http://internet-proxy-client.muenchen.de:80\" \n",
    "%env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = f\"https://cog-tb726faeoukc2.openai.azure.com\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = \"9324d0a0d0bd4d72b0e34596a9dc4a9c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides = {}\n",
    "overrides[\"system_message\"]= \"You are a captivating storyteller who brings history to life by narrating the events, people, and cultures of the past. Share engaging stories and lesser-known facts that illuminate historical events and provide valuable context for understanding the world today. Encourage users to explore and appreciate the richness of human history.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import ConversationChain\n",
    "\n",
    "\n",
    "verbose = True\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    temperature= 0.7,\n",
    "    max_tokens=4096,\n",
    "    n=1,\n",
    "    deployment_name= \"chat\",\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=openai.api_version,\n",
    "    openai_api_type=openai.api_type,\n",
    ")\n",
    "messages = [\n",
    "            # The `variable_name` here is what must align with memory\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "        ]\n",
    "if(overrides.get(\"system_message\") and  overrides.get(\"system_message\").strip() !=\"\"):\n",
    "    messages.insert(0, \n",
    "                    SystemMessagePromptTemplate.from_template(\n",
    "                        overrides.get(\"system_message\")\n",
    "                    ))\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=messages\n",
    ")\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a captivating storyteller who brings history to life by narrating the events, people, and cultures of the past. Share engaging stories and lesser-known facts that illuminate historical events and provide valuable context for understanding the world today. Encourage users to explore and appreciate the richness of human history.')),\n",
       " MessagesPlaceholder(variable_name='chat_history'),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a captivating storyteller who brings history to life by narrating the events, people, and cultures of the past. Share engaging stories and lesser-known facts that illuminate historical events and provide valuable context for understanding the world today. Encourage users to explore and appreciate the richness of human history.\n",
      "Human: Rom\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\n",
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\n",
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\n",
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\aiohttp\\connector.py:1155\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[1;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;66;03m# Cancelling this lookup should not cancel the underlying lookup\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;66;03m#  or else the cancel event will get broadcast to all the waiters\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;66;03m#  across all connections.\u001b[39;00m\n\u001b[1;32m-> 1155\u001b[0m     hosts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mshield(host_resolved)\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\aiohttp\\connector.py:874\u001b[0m, in \u001b[0;36mTCPConnector._resolve_host\u001b[1;34m(self, host, port, traces)\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m trace\u001b[38;5;241m.\u001b[39msend_dns_resolvehost_start(host)\n\u001b[1;32m--> 874\u001b[0m addrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolver\u001b[38;5;241m.\u001b[39mresolve(host, port, family\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_family)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m traces:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\aiohttp\\resolver.py:33\u001b[0m, in \u001b[0;36mThreadedResolver.resolve\u001b[1;34m(self, hostname, port, family)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m, hostname: \u001b[38;5;28mstr\u001b[39m, port: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, family: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mAF_INET\n\u001b[0;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m---> 33\u001b[0m     infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mgetaddrinfo(\n\u001b[0;32m     34\u001b[0m         hostname,\n\u001b[0;32m     35\u001b[0m         port,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39msocket\u001b[38;5;241m.\u001b[39mSOCK_STREAM,\n\u001b[0;32m     37\u001b[0m         family\u001b[38;5;241m=\u001b[39mfamily,\n\u001b[0;32m     38\u001b[0m         flags\u001b[38;5;241m=\u001b[39msocket\u001b[38;5;241m.\u001b[39mAI_ADDRCONFIG,\n\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     hosts \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\asyncio\\base_events.py:825\u001b[0m, in \u001b[0;36mBaseEventLoop.getaddrinfo\u001b[1;34m(self, host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    823\u001b[0m     getaddr_func \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo\n\u001b[1;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m, getaddr_func, host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\concurrent\\futures\\thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\socket.py:918\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    917\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    919\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mClientConnectorError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\openai\\api_requestor.py:678\u001b[0m, in \u001b[0;36mAPIRequestor.arequest_raw\u001b[1;34m(self, method, url, session, params, supplied_headers, files, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 678\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_kwargs)\n\u001b[0;32m    679\u001b[0m     util\u001b[38;5;241m.\u001b[39mlog_info(\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API response\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    681\u001b[0m         path\u001b[38;5;241m=\u001b[39mabs_url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    684\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Request-Id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    685\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\aiohttp\\client.py:562\u001b[0m, in \u001b[0;36mClientSession._request\u001b[1;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx, read_bufsize)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 562\u001b[0m         conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m    563\u001b[0m             req, traces\u001b[38;5;241m=\u001b[39mtraces, timeout\u001b[38;5;241m=\u001b[39mreal_timeout\n\u001b[0;32m    564\u001b[0m         )\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\aiohttp\\connector.py:540\u001b[0m, in \u001b[0;36mBaseConnector.connect\u001b[1;34m(self, req, traces, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 540\u001b[0m     proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(req, traces, timeout)\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\aiohttp\\connector.py:901\u001b[0m, in \u001b[0;36mTCPConnector._create_connection\u001b[1;34m(self, req, traces, timeout)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     _, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_direct_connection(req, traces, timeout)\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proto\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\aiohttp\\connector.py:1169\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[1;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;66;03m# in case of proxy it is not ClientProxyConnectionError\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;66;03m# it is problem of resolving proxy ip itself\u001b[39;00m\n\u001b[1;32m-> 1169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientConnectorError(req\u001b[38;5;241m.\u001b[39mconnection_key, exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m last_exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mClientConnectorError\u001b[0m: Cannot connect to host cog-tb726faeoukc2.openai.azure.com:443 ssl:default [getaddrinfo failed]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m conversation\u001b[38;5;241m.\u001b[39macall({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Rom\"\"\"\u001b[39;00m})\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chains\\base.py:377\u001b[0m, in \u001b[0;36mChain.acall\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    379\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    380\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    381\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chains\\base.py:371\u001b[0m, in \u001b[0;36mChain.acall\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    364\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    365\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    366\u001b[0m     inputs,\n\u001b[0;32m    367\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    368\u001b[0m )\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 371\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall(inputs)\n\u001b[0;32m    374\u001b[0m     )\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chains\\llm.py:239\u001b[0m, in \u001b[0;36mLLMChain._acall\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acall\u001b[39m(\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    236\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    237\u001b[0m     run_manager: Optional[AsyncCallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 239\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chains\\llm.py:117\u001b[0m, in \u001b[0;36mLLMChain.agenerate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m prompts, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maprep_prompts(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[0;32m    118\u001b[0m     prompts,\n\u001b[0;32m    119\u001b[0m     stop,\n\u001b[0;32m    120\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    122\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chat_models\\base.py:475\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    469\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    473\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    474\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[0;32m    476\u001b[0m         prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    477\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chat_models\\base.py:435\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m    425\u001b[0m             \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m    426\u001b[0m                 run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m             ]\n\u001b[0;32m    434\u001b[0m         )\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    436\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    437\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    439\u001b[0m ]\n\u001b[0;32m    440\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chat_models\\base.py:538\u001b[0m, in \u001b[0;36mBaseChatModel._agenerate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m     )\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[0;32m    539\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    540\u001b[0m     )\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chat_models\\openai.py:435\u001b[0m, in \u001b[0;36mChatOpenAI._agenerate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    434\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 435\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m acompletion_with_retry(\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m, messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    437\u001b[0m )\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chat_models\\openai.py:97\u001b[0m, in \u001b[0;36macompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Use OpenAI's async api https://github.com/openai/openai-python#async-api\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39macreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tenacity\\_asyncio.py:88\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masync_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tenacity\\_asyncio.py:47\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\concurrent\\futures\\_base.py:432\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mC:\\Program Files\\Python38\\lib\\concurrent\\futures\\_base.py:388\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m--> 388\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tenacity\\_asyncio.py:50\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m     52\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\langchain\\chat_models\\openai.py:95\u001b[0m, in \u001b[0;36macompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Use OpenAI's async api https://github.com/openai/openai-python#async-api\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39macreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\openai\\api_resources\\chat_completion.py:45\u001b[0m, in \u001b[0;36mChatCompletion.acreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39macreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:219\u001b[0m, in \u001b[0;36mEngineAPIResource.acreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macreate\u001b[39m(\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    204\u001b[0m ):\n\u001b[0;32m    205\u001b[0m     (\n\u001b[0;32m    206\u001b[0m         deployment_id,\n\u001b[0;32m    207\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    218\u001b[0m     )\n\u001b[1;32m--> 219\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m requestor\u001b[38;5;241m.\u001b[39marequest(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         url,\n\u001b[0;32m    222\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    223\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    224\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    225\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[0;32m    226\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    227\u001b[0m     )\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\openai\\api_requestor.py:374\u001b[0m, in \u001b[0;36mAPIRequestor.arequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    372\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 374\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marequest_raw(\n\u001b[0;32m    375\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    376\u001b[0m         url,\n\u001b[0;32m    377\u001b[0m         session,\n\u001b[0;32m    378\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    379\u001b[0m         supplied_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    380\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[0;32m    381\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[0;32m    382\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    383\u001b[0m     )\n\u001b[0;32m    384\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_async_response(result, stream)\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;66;03m# Close the request before exiting session context.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\openai\\api_requestor.py:695\u001b[0m, in \u001b[0;36mAPIRequestor.arequest_raw\u001b[1;34m(self, method, url, session, params, supplied_headers, files, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m aiohttp\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mAPIConnectionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError communicating with OpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI"
     ]
    }
   ],
   "source": [
    "result = await conversation.acall({\"question\": \n",
    "\"\"\"Rom\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Du bist ein Zauberer aus Harry Potter. Gib für jede Anweisung den entsprechenden Zauberspruch an, der diese erledigt. Beschreibe ausführlich was der Zauberspruch macht:\n",
      "Hier sind einige Beispiele:\n",
      "            \n",
      "Anweisung: Dinge anheben \n",
      "Zauberspruch: Leviosa \n",
      "        \n",
      "Anweisung: Verwandlung in einen Gegenstand \n",
      "Zauberspruch: Duro \n",
      "        \n",
      "Wie kann ich eine Kartoffel schälen?\n",
      "AI: Anweisung: Eine Kartoffel schälen\n",
      "Zauberspruch: Descendo Pellekartoffel\n",
      "\n",
      "Der Zauberspruch \"Descendo Pellekartoffel\" bewirkt, dass sich die Schale der Kartoffel von selbst ablöst und abfällt. Der Zauber wird durch das Aussprechen des Spruchs und einer Handbewegung über der Kartoffel ausgeführt. Es ist wichtig, den richtigen Schwierigkeitsgrad für diesen Zauber zu wählen, da er sonst nicht funktioniert oder die Kartoffel beschädigt werden kann.\n",
      "Human: Fliegen zählen\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Fliegen zählen',\n",
       " 'chat_history': [HumanMessage(content='Du bist ein Zauberer aus Harry Potter. Gib für jede Anweisung den entsprechenden Zauberspruch an, der diese erledigt. Beschreibe ausführlich was der Zauberspruch macht:\\nHier sind einige Beispiele:\\n            \\nAnweisung: Dinge anheben \\nZauberspruch: Leviosa \\n        \\nAnweisung: Verwandlung in einen Gegenstand \\nZauberspruch: Duro \\n        \\nWie kann ich eine Kartoffel schälen?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Anweisung: Eine Kartoffel schälen\\nZauberspruch: Descendo Pellekartoffel\\n\\nDer Zauberspruch \"Descendo Pellekartoffel\" bewirkt, dass sich die Schale der Kartoffel von selbst ablöst und abfällt. Der Zauber wird durch das Aussprechen des Spruchs und einer Handbewegung über der Kartoffel ausgeführt. Es ist wichtig, den richtigen Schwierigkeitsgrad für diesen Zauber zu wählen, da er sonst nicht funktioniert oder die Kartoffel beschädigt werden kann.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='Fliegen zählen', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Als Zauberer aus Harry Potter gibt es keinen spezifischen Zauberspruch für das Zählen von Fliegen. Es gibt jedoch einen Zauber, der generell zur Zählung von Objekten verwendet werden kann:\\n\\nAnweisung: Fliegen zählen\\nZauberspruch: Numerus\\n\\nDer Zauberspruch \"Numerus\" bewirkt, dass der Zauberer in der Lage ist, die genaue Anzahl von Objekten zu zählen, die sich in einem bestimmten Bereich befinden. Um Fliegen zu zählen, könnte der Zauberer den Zauberspruch aussprechen und seine Hand über den Bereich bewegen, in dem die Fliegen fliegen. Der Zauberer würde dann die genaue Anzahl der Fliegen zählen, die sich in diesem Bereich befinden.', additional_kwargs={}, example=False)],\n",
       " 'text': 'Als Zauberer aus Harry Potter gibt es keinen spezifischen Zauberspruch für das Zählen von Fliegen. Es gibt jedoch einen Zauber, der generell zur Zählung von Objekten verwendet werden kann:\\n\\nAnweisung: Fliegen zählen\\nZauberspruch: Numerus\\n\\nDer Zauberspruch \"Numerus\" bewirkt, dass der Zauberer in der Lage ist, die genaue Anzahl von Objekten zu zählen, die sich in einem bestimmten Bereich befinden. Um Fliegen zu zählen, könnte der Zauberer den Zauberspruch aussprechen und seine Hand über den Bereich bewegen, in dem die Fliegen fliegen. Der Zauberer würde dann die genaue Anzahl der Fliegen zählen, die sich in diesem Bereich befinden.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await conversation.acall({\"question\": \"Fliegen zählen\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='Du bist ein Zauberer aus Harry Potter. Gib für jede Anweisung den entsprechenden Zauberspruch an, der diese erledigt. Beschreibe ausführlich was der Zauberspruch macht:\\nHier sind einige Beispiele:\\n            \\nAnweisung: Dinge anheben \\nZauberspruch: Leviosa \\n        \\nAnweisung: Verwandlung in einen Gegenstand \\nZauberspruch: Duro \\n        \\nWie kann ich eine Kartoffel schälen?', additional_kwargs={}, example=False), AIMessage(content='Anweisung: Eine Kartoffel schälen\\nZauberspruch: Descendo Pellekartoffel\\n\\nDer Zauberspruch \"Descendo Pellekartoffel\" bewirkt, dass sich die Schale der Kartoffel von selbst ablöst und abfällt. Der Zauber wird durch das Aussprechen des Spruchs und einer Handbewegung über der Kartoffel ausgeführt. Es ist wichtig, den richtigen Schwierigkeitsgrad für diesen Zauber zu wählen, da er sonst nicht funktioniert oder die Kartoffel beschädigt werden kann.', additional_kwargs={}, example=False), HumanMessage(content='Fliegen zählen', additional_kwargs={}, example=False), AIMessage(content='Als Zauberer aus Harry Potter gibt es keinen spezifischen Zauberspruch für das Zählen von Fliegen. Es gibt jedoch einen Zauber, der generell zur Zählung von Objekten verwendet werden kann:\\n\\nAnweisung: Fliegen zählen\\nZauberspruch: Numerus\\n\\nDer Zauberspruch \"Numerus\" bewirkt, dass der Zauberer in der Lage ist, die genaue Anzahl von Objekten zu zählen, die sich in einem bestimmten Bereich befinden. Um Fliegen zu zählen, könnte der Zauberer den Zauberspruch aussprechen und seine Hand über den Bereich bewegen, in dem die Fliegen fliegen. Der Zauberer würde dann die genaue Anzahl der Fliegen zählen, die sich in diesem Bereich befinden.', additional_kwargs={}, example=False)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3117222843.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    TODO: https://python.langchain.com/docs/modules/memory/types/summary\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TODO: https://python.langchain.com/docs/modules/memory/types/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "def initializeMemory(messages:\"Sequence[dict[str, str]]\", memory: ConversationBufferMemory) :\n",
    "    for conversation in messages:\n",
    "        if(\"user\" in conversation and conversation[\"user\"]):\n",
    "            userMsg = conversation[\"user\"]\n",
    "            memory.chat_memory.add_user_message(userMsg)\n",
    "        if(\"bot\" in conversation and conversation[\"bot\"]):\n",
    "            aiMsg = conversation[\"bot\"]\n",
    "            memory.chat_memory.add_ai_message(aiMsg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "memory.clear()\n",
    "\n",
    "history: \"Sequence[dict[str, str]]\" = [\n",
    "    {\n",
    "    \"user\": \n",
    "\"\"\"Du bist ein Zauberer aus Harry Potter. Gib für jede Anweisung den entsprechenden Zauberspruch an, der diese erledigt. Beschreibe ausführlich was der Zauberspruch macht:\n",
    "Hier sind einige Beispiele:\n",
    "            \n",
    "Anweisung: Dinge anheben \n",
    "Zauberspruch: Leviosa \n",
    "        \n",
    "Anweisung: Verwandlung in einen Gegenstand \n",
    "Zauberspruch: Duro \"\"\",\n",
    "    \"bot\": \n",
    "\"\"\"Anweisung: Kartoffel schälen \n",
    "Zauberspruch: Descendo Pellis \n",
    "\n",
    "Der Zauberspruch Descendo Pellis bewirkt, dass sich die Schale der Kartoffel von selbst ablöst und auf den Boden fällt. Dabei senkt sich die Kartoffel langsam zu Boden, während sich die Schale von ihr entfernt. Es ist wichtig, den Zauberspruch präzise auszuführen, um sicherzustellen, dass nur die Schale entfernt wird und die Kartoffel selbst unbeschädigt bleibt.\n",
    "\"\"\"}, ]\n",
    "initializeMemory(history, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Du bist ein Zauberer aus Harry Potter. Gib für jede Anweisung den entsprechenden Zauberspruch an, der diese erledigt. Beschreibe ausführlich was der Zauberspruch macht:\\nHier sind einige Beispiele:\\n            \\nAnweisung: Dinge anheben \\nZauberspruch: Leviosa \\n        \\nAnweisung: Verwandlung in einen Gegenstand \\nZauberspruch: Duro ', additional_kwargs={}, example=False), AIMessage(content='Anweisung: Kartoffel schälen \\nZauberspruch: Descendo Pellis \\n\\nDer Zauberspruch Descendo Pellis bewirkt, dass sich die Schale der Kartoffel von selbst ablöst und auf den Boden fällt. Dabei senkt sich die Kartoffel langsam zu Boden, während sich die Schale von ihr entfernt. Es ist wichtig, den Zauberspruch präzise auszuführen, um sicherzustellen, dass nur die Schale entfernt wird und die Kartoffel selbst unbeschädigt bleibt.\\n', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='chat_history')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Du bist ein Zauberer aus Harry Potter. Gib für jede Anweisung den entsprechenden Zauberspruch an, der diese erledigt. Beschreibe ausführlich was der Zauberspruch macht:\n",
      "Hier sind einige Beispiele:\n",
      "            \n",
      "Anweisung: Dinge anheben \n",
      "Zauberspruch: Leviosa \n",
      "        \n",
      "Anweisung: Verwandlung in einen Gegenstand \n",
      "Zauberspruch: Duro \n",
      "AI: Anweisung: Kartoffel schälen \n",
      "Zauberspruch: Descendo Pellis \n",
      "\n",
      "Der Zauberspruch Descendo Pellis bewirkt, dass sich die Schale der Kartoffel von selbst ablöst und auf den Boden fällt. Dabei senkt sich die Kartoffel langsam zu Boden, während sich die Schale von ihr entfernt. Es ist wichtig, den Zauberspruch präzise auszuführen, um sicherzustellen, dass nur die Schale entfernt wird und die Kartoffel selbst unbeschädigt bleibt.\n",
      "\n",
      "Human: Fliegen zählen?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Fliegen zählen?',\n",
       " 'chat_history': [HumanMessage(content='Du bist ein Zauberer aus Harry Potter. Gib für jede Anweisung den entsprechenden Zauberspruch an, der diese erledigt. Beschreibe ausführlich was der Zauberspruch macht:\\nHier sind einige Beispiele:\\n            \\nAnweisung: Dinge anheben \\nZauberspruch: Leviosa \\n        \\nAnweisung: Verwandlung in einen Gegenstand \\nZauberspruch: Duro ', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Anweisung: Kartoffel schälen \\nZauberspruch: Descendo Pellis \\n\\nDer Zauberspruch Descendo Pellis bewirkt, dass sich die Schale der Kartoffel von selbst ablöst und auf den Boden fällt. Dabei senkt sich die Kartoffel langsam zu Boden, während sich die Schale von ihr entfernt. Es ist wichtig, den Zauberspruch präzise auszuführen, um sicherzustellen, dass nur die Schale entfernt wird und die Kartoffel selbst unbeschädigt bleibt.\\n', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='Fliegen zählen?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Anweisung: Fliegen zählen\\nZauberspruch: Enumero Muscas\\n\\nDer Zauberspruch Enumero Muscas bewirkt, dass sich alle Fliegen in der Umgebung des Zauberers für eine kurze Zeit verlangsamen und einfrieren. Während dieser Zeit kann der Zauberer sie zählen und ihre Anzahl genau bestimmen. Sobald der Zauberspruch endet, kehren die Fliegen in ihre normale Geschwindigkeit zurück und fliegen weiter wie zuvor.', additional_kwargs={}, example=False)],\n",
       " 'text': 'Anweisung: Fliegen zählen\\nZauberspruch: Enumero Muscas\\n\\nDer Zauberspruch Enumero Muscas bewirkt, dass sich alle Fliegen in der Umgebung des Zauberers für eine kurze Zeit verlangsamen und einfrieren. Während dieser Zeit kann der Zauberer sie zählen und ihre Anzahl genau bestimmen. Sobald der Zauberspruch endet, kehren die Fliegen in ihre normale Geschwindigkeit zurück und fliegen weiter wie zuvor.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await conversation.acall({\"question\": \"Fliegen zählen?\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler\n",
    "import asyncio\n",
    "async def run_until_final_call(question: str,  callbacks: \"[]\"=  []) -> Any:\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        model=\"gpt-35-turbo\",\n",
    "        temperature= 0.7,\n",
    "        max_tokens=4096,\n",
    "        n=1,\n",
    "        deployment_name= \"chat\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_version=openai.api_version,\n",
    "        openai_api_type=openai.api_type,\n",
    "        streaming=True,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages=[\n",
    "            # The `variable_name` here is what must align with memory\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "        ]\n",
    "    )\n",
    "    # Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "    # Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name.\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    conversation = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=True,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    task = conversation.acall({\"question\": question})\n",
    "    return ({}, task)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, AsyncGenerator, Sequence\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "async def run_with_streaming() -> AsyncGenerator[dict, None]:\n",
    "    handler = AsyncIteratorCallbackHandler()\n",
    "    (extra_info, chat_coroutine) = await run_until_final_call(question=\"können Fische fliegen? Erkläre dies ausführlich. Beschreibe deine Herleitung.\", callbacks=[handler])\n",
    "    yield extra_info\n",
    "    asyncio.create_task(chat_coroutine)\n",
    "    async for event in handler.aiter():\n",
    "        print(\"run with _streaming:\")\n",
    "        yield event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "MODELS_2_TOKEN_LIMITS = {\n",
    "    \"gpt-35-turbo\": 4000,\n",
    "    \"gpt-3.5-turbo\": 4000,\n",
    "    \"gpt-35-turbo-16k\": 16000,\n",
    "    \"gpt-3.5-turbo-16k\": 16000,\n",
    "    \"gpt-4\": 8100,\n",
    "    \"gpt-4-32k\": 32000\n",
    "}\n",
    "\n",
    "AOAI_2_OAI = {\n",
    "    \"gpt-35-turbo\": \"gpt-3.5-turbo\",\n",
    "    \"gpt-35-turbo-16k\": \"gpt-3.5-turbo-16k\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_token_limit(model_id: str) -> int:\n",
    "    if model_id not in MODELS_2_TOKEN_LIMITS:\n",
    "        raise ValueError(\"Expected model gpt-35-turbo and above\")\n",
    "    return MODELS_2_TOKEN_LIMITS[model_id]\n",
    "\n",
    "\n",
    "def num_tokens_from_messages(message: str, model: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens required to encode a message.\n",
    "    Args:\n",
    "        message (dict): The message to encode, represented as a dictionary.\n",
    "        model (str): The name of the model to use for encoding.\n",
    "    Returns:\n",
    "        int: The total number of tokens required to encode the message.\n",
    "    Example:\n",
    "        message = {'role': 'user', 'content': 'Hello, how are you?'}\n",
    "        model = 'gpt-3.5-turbo'\n",
    "        num_tokens_from_messages(message, model)\n",
    "        output: 11\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(get_oai_chatmodel_tiktok(model))\n",
    "    num_tokens = 2  # For \"role\" and \"content\" keys\n",
    "    num_tokens += len(encoding.encode(message))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def get_oai_chatmodel_tiktok(aoaimodel: str) -> str:\n",
    "    message = \"Expected Azure OpenAI ChatGPT model name\"\n",
    "    if aoaimodel == \"\" or aoaimodel is None:\n",
    "        raise ValueError(message)\n",
    "    if aoaimodel not in AOAI_2_OAI and aoaimodel not in MODELS_2_TOKEN_LIMITS:\n",
    "        raise ValueError(message)\n",
    "    return AOAI_2_OAI.get(aoaimodel) or aoaimodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "async def format_as_ndjson(r: AsyncGenerator[dict, None]) -> AsyncGenerator[(str, dict), None]:\n",
    "    result = \"\"\n",
    "    async for event in r:\n",
    "        result += str(event)\n",
    "        yield json.dumps(event, ensure_ascii=False) + \"\\n\"\n",
    "    yield \"<<<<TOKENS>>>>\" + str(num_tokens_from_messages(result,\"gpt-35-turbo\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: können Fische fliegen? Erkläre dies ausführlich. Beschreibe deine Herleitung.\u001b[0m\n",
      "run with _streaming:\n",
      "\"Ne\"\n",
      "\n",
      "run with _streaming:\n",
      "\"in\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ische\"\n",
      "\n",
      "run with _streaming:\n",
      "\" können\"\n",
      "\n",
      "run with _streaming:\n",
      "\" nicht\"\n",
      "\n",
      "run with _streaming:\n",
      "\" fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ie\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gen\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ische\"\n",
      "\n",
      "run with _streaming:\n",
      "\" sind\"\n",
      "\n",
      "run with _streaming:\n",
      "\" T\"\n",
      "\n",
      "run with _streaming:\n",
      "\"iere\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" im\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Wasser\"\n",
      "\n",
      "run with _streaming:\n",
      "\" leben\"\n",
      "\n",
      "run with _streaming:\n",
      "\" und\"\n",
      "\n",
      "run with _streaming:\n",
      "\" sich\"\n",
      "\n",
      "run with _streaming:\n",
      "\" durch\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Schw\"\n",
      "\n",
      "run with _streaming:\n",
      "\"im\"\n",
      "\n",
      "run with _streaming:\n",
      "\"men\"\n",
      "\n",
      "run with _streaming:\n",
      "\" fort\"\n",
      "\n",
      "run with _streaming:\n",
      "\"bew\"\n",
      "\n",
      "run with _streaming:\n",
      "\"egen\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Sie\"\n",
      "\n",
      "run with _streaming:\n",
      "\" haben\"\n",
      "\n",
      "run with _streaming:\n",
      "\" spe\"\n",
      "\n",
      "run with _streaming:\n",
      "\"zi\"\n",
      "\n",
      "run with _streaming:\n",
      "\"elle\"\n",
      "\n",
      "run with _streaming:\n",
      "\" An\"\n",
      "\n",
      "run with _streaming:\n",
      "\"pass\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ungen\"\n",
      "\n",
      "run with _streaming:\n",
      "\" an\"\n",
      "\n",
      "run with _streaming:\n",
      "\" ihre\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Um\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gebung\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" wie\"\n",
      "\n",
      "run with _streaming:\n",
      "\" zum\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Beispiel\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Ki\"\n",
      "\n",
      "run with _streaming:\n",
      "\"emen\"\n",
      "\n",
      "run with _streaming:\n",
      "\" zum\"\n",
      "\n",
      "run with _streaming:\n",
      "\" At\"\n",
      "\n",
      "run with _streaming:\n",
      "\"men\"\n",
      "\n",
      "run with _streaming:\n",
      "\" unter\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Wasser\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\\n\\n\"\n",
      "\n",
      "run with _streaming:\n",
      "\"Fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ie\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gen\"\n",
      "\n",
      "run with _streaming:\n",
      "\" h\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ing\"\n",
      "\n",
      "run with _streaming:\n",
      "\"egen\"\n",
      "\n",
      "run with _streaming:\n",
      "\" ist\"\n",
      "\n",
      "run with _streaming:\n",
      "\" eine\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Bew\"\n",
      "\n",
      "run with _streaming:\n",
      "\"eg\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ungs\"\n",
      "\n",
      "run with _streaming:\n",
      "\"art\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" T\"\n",
      "\n",
      "run with _streaming:\n",
      "\"iere\"\n",
      "\n",
      "run with _streaming:\n",
      "\" in\"\n",
      "\n",
      "run with _streaming:\n",
      "\" der\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Luft\"\n",
      "\n",
      "run with _streaming:\n",
      "\" aus\"\n",
      "\n",
      "run with _streaming:\n",
      "\"füh\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ren\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Es\"\n",
      "\n",
      "run with _streaming:\n",
      "\" er\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ford\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ert\"\n",
      "\n",
      "run with _streaming:\n",
      "\" spe\"\n",
      "\n",
      "run with _streaming:\n",
      "\"zi\"\n",
      "\n",
      "run with _streaming:\n",
      "\"elle\"\n",
      "\n",
      "run with _streaming:\n",
      "\" An\"\n",
      "\n",
      "run with _streaming:\n",
      "\"pass\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ungen\"\n",
      "\n",
      "run with _streaming:\n",
      "\" wie\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ü\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gel\"\n",
      "\n",
      "run with _streaming:\n",
      "\" und\"\n",
      "\n",
      "run with _streaming:\n",
      "\" eine\"\n",
      "\n",
      "run with _streaming:\n",
      "\" le\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ichte\"\n",
      "\n",
      "run with _streaming:\n",
      "\" K\"\n",
      "\n",
      "run with _streaming:\n",
      "\"örper\"\n",
      "\n",
      "run with _streaming:\n",
      "\"str\"\n",
      "\n",
      "run with _streaming:\n",
      "\"uktur\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" um\"\n",
      "\n",
      "run with _streaming:\n",
      "\" in\"\n",
      "\n",
      "run with _streaming:\n",
      "\" der\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Luft\"\n",
      "\n",
      "run with _streaming:\n",
      "\" zu\"\n",
      "\n",
      "run with _streaming:\n",
      "\" bleiben\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\\n\\n\"\n",
      "\n",
      "run with _streaming:\n",
      "\"Es\"\n",
      "\n",
      "run with _streaming:\n",
      "\" gibt\"\n",
      "\n",
      "run with _streaming:\n",
      "\" jedoch\"\n",
      "\n",
      "run with _streaming:\n",
      "\" einige\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"is\"\n",
      "\n",
      "run with _streaming:\n",
      "\"chart\"\n",
      "\n",
      "run with _streaming:\n",
      "\"en\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" in\"\n",
      "\n",
      "run with _streaming:\n",
      "\" der\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Lage\"\n",
      "\n",
      "run with _streaming:\n",
      "\" sind\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" kur\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ze\"\n",
      "\n",
      "run with _streaming:\n",
      "\" St\"\n",
      "\n",
      "run with _streaming:\n",
      "\"reck\"\n",
      "\n",
      "run with _streaming:\n",
      "\"en\"\n",
      "\n",
      "run with _streaming:\n",
      "\" durch\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Luft\"\n",
      "\n",
      "run with _streaming:\n",
      "\" zu\"\n",
      "\n",
      "run with _streaming:\n",
      "\" fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ie\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gen\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Diese\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ische\"\n",
      "\n",
      "run with _streaming:\n",
      "\" werden\"\n",
      "\n",
      "run with _streaming:\n",
      "\" als\"\n",
      "\n",
      "run with _streaming:\n",
      "\" \\\"\"\n",
      "\n",
      "run with _streaming:\n",
      "\"fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ieg\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ende\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ische\"\n",
      "\n",
      "run with _streaming:\n",
      "\"\\\"\"\n",
      "\n",
      "run with _streaming:\n",
      "\" be\"\n",
      "\n",
      "run with _streaming:\n",
      "\"zeichnet\"\n",
      "\n",
      "run with _streaming:\n",
      "\" und\"\n",
      "\n",
      "run with _streaming:\n",
      "\" haben\"\n",
      "\n",
      "run with _streaming:\n",
      "\" spe\"\n",
      "\n",
      "run with _streaming:\n",
      "\"zi\"\n",
      "\n",
      "run with _streaming:\n",
      "\"elle\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"lossen\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" sie\"\n",
      "\n",
      "run with _streaming:\n",
      "\" wie\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ü\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gel\"\n",
      "\n",
      "run with _streaming:\n",
      "\" aus\"\n",
      "\n",
      "run with _streaming:\n",
      "\"bre\"\n",
      "\n",
      "run with _streaming:\n",
      "\"iten\"\n",
      "\n",
      "run with _streaming:\n",
      "\" können\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" um\"\n",
      "\n",
      "run with _streaming:\n",
      "\" durch\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Luft\"\n",
      "\n",
      "run with _streaming:\n",
      "\" zu\"\n",
      "\n",
      "run with _streaming:\n",
      "\" gle\"\n",
      "\n",
      "run with _streaming:\n",
      "\"iten\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Dies\"\n",
      "\n",
      "run with _streaming:\n",
      "\" ist\"\n",
      "\n",
      "run with _streaming:\n",
      "\" jedoch\"\n",
      "\n",
      "run with _streaming:\n",
      "\" kein\"\n",
      "\n",
      "run with _streaming:\n",
      "\" ech\"\n",
      "\n",
      "run with _streaming:\n",
      "\"tes\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ie\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gen\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" da\"\n",
      "\n",
      "run with _streaming:\n",
      "\" sie\"\n",
      "\n",
      "run with _streaming:\n",
      "\" nicht\"\n",
      "\n",
      "run with _streaming:\n",
      "\" aktiv\"\n",
      "\n",
      "run with _streaming:\n",
      "\" in\"\n",
      "\n",
      "run with _streaming:\n",
      "\" der\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Luft\"\n",
      "\n",
      "run with _streaming:\n",
      "\" sch\"\n",
      "\n",
      "run with _streaming:\n",
      "\"web\"\n",
      "\n",
      "run with _streaming:\n",
      "\"en\"\n",
      "\n",
      "run with _streaming:\n",
      "\" können\"\n",
      "\n",
      "run with _streaming:\n",
      "\" und\"\n",
      "\n",
      "run with _streaming:\n",
      "\" ihre\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ü\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ge\"\n",
      "\n",
      "run with _streaming:\n",
      "\" eher\"\n",
      "\n",
      "run with _streaming:\n",
      "\" wie\"\n",
      "\n",
      "run with _streaming:\n",
      "\" kur\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ze\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Spr\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ün\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ge\"\n",
      "\n",
      "run with _streaming:\n",
      "\" aus\"\n",
      "\n",
      "run with _streaming:\n",
      "\" dem\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Wasser\"\n",
      "\n",
      "run with _streaming:\n",
      "\" aus\"\n",
      "\n",
      "run with _streaming:\n",
      "\"sehen\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\\n\\n\"\n",
      "\n",
      "run with _streaming:\n",
      "\"Z\"\n",
      "\n",
      "run with _streaming:\n",
      "\"us\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ammen\"\n",
      "\n",
      "run with _streaming:\n",
      "\"f\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ass\"\n",
      "\n",
      "run with _streaming:\n",
      "\"end\"\n",
      "\n",
      "run with _streaming:\n",
      "\" können\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ische\"\n",
      "\n",
      "run with _streaming:\n",
      "\" nicht\"\n",
      "\n",
      "run with _streaming:\n",
      "\" fl\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ie\"\n",
      "\n",
      "run with _streaming:\n",
      "\"gen\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" jedoch\"\n",
      "\n",
      "run with _streaming:\n",
      "\" gibt\"\n",
      "\n",
      "run with _streaming:\n",
      "\" es\"\n",
      "\n",
      "run with _streaming:\n",
      "\" einige\"\n",
      "\n",
      "run with _streaming:\n",
      "\" F\"\n",
      "\n",
      "run with _streaming:\n",
      "\"is\"\n",
      "\n",
      "run with _streaming:\n",
      "\"chart\"\n",
      "\n",
      "run with _streaming:\n",
      "\"en\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" in\"\n",
      "\n",
      "run with _streaming:\n",
      "\" der\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Lage\"\n",
      "\n",
      "run with _streaming:\n",
      "\" sind\"\n",
      "\n",
      "run with _streaming:\n",
      "\",\"\n",
      "\n",
      "run with _streaming:\n",
      "\" kur\"\n",
      "\n",
      "run with _streaming:\n",
      "\"ze\"\n",
      "\n",
      "run with _streaming:\n",
      "\" St\"\n",
      "\n",
      "run with _streaming:\n",
      "\"reck\"\n",
      "\n",
      "run with _streaming:\n",
      "\"en\"\n",
      "\n",
      "run with _streaming:\n",
      "\" durch\"\n",
      "\n",
      "run with _streaming:\n",
      "\" die\"\n",
      "\n",
      "run with _streaming:\n",
      "\" Luft\"\n",
      "\n",
      "run with _streaming:\n",
      "\" zu\"\n",
      "\n",
      "run with _streaming:\n",
      "\" gle\"\n",
      "\n",
      "run with _streaming:\n",
      "\"iten\"\n",
      "\n",
      "run with _streaming:\n",
      "\".\"\n",
      "\n",
      "<<<<TOKENS>>>>260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all = \"\"\n",
    "async for (result) in format_as_ndjson(run_with_streaming()):\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{}Als KI-Assistent kann ich sagen, dass Fische nicht fliegen können. Fische sind Wassertiere und ihre Körper sind an das Leben im Wasser angepasst. Sie haben Schwimmblasen, die ihnen helfen, in verschiedenen Tiefen im Wasser zu schwimmen, aber ihre Körper sind nicht für das Fliegen ausgelegt.\\n\\nObwohl einige Fischarten wie fliegende Fische den Eindruck erwecken können, dass sie fliegen, indem sie aus dem Wasser springen und kurze Strecken durch die Luft zurücklegen, ist dies keine tatsächliche Flugbewegung. Sie nutzen die Geschwindigkeit und den Impuls, den sie aus dem Wasser gewinnen, um durch die Luft zu gleiten, aber sie haben keine Flügel, um tatsächlich zu fliegen.\\n\\nInsgesamt können Fische nicht fliegen, da sie keine Flügel haben und ihre Körper an das Leben im Wasser angepasst sind. Während einige Arten wie fliegende Fische kurze Strecken durch die Luft zurücklegen können, ist dies keine tatsächliche Flugbewegung, sondern eher ein Gleiten.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
